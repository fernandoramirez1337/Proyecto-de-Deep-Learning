{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB1m8aNrXDoT"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandoramirez1337/Proyecto-de-Deep-Learning/blob/claude%2Fimprove-implementation-018rMkv8JP1bb2KNiHNbvF1o/Hybrid_CNN_LSTM_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVYVPon2XDoU"
      },
      "source": [
        "# Deep Hybrid CNN-LSTM ArXiv Classification\n",
        "\n",
        "**3-Class Model:** cs.AI-LG, cs.CL, cs.CV\n",
        "\n",
        "## Deep Architecture (Maximum Performance)\n",
        "\n",
        "**Title Processing:**\n",
        "- **3-layer Bidirectional LSTM** (160 hidden units, 6 total layers)\n",
        "- **Multi-head self-attention (8 heads)** over LSTM outputs\n",
        "- Layer normalization with residual connections\n",
        "\n",
        "**Abstract Processing:**\n",
        "- **9 Dilated Residual CNN blocks** with kernel sizes [3, 4, 5] × dilations [1, 2, 4]\n",
        "- 160 filters per block (1440 total features)\n",
        "- Skip connections and batch normalization\n",
        "- **Multi-head global attention (8 heads)** over CNN features\n",
        "\n",
        "**Character-Level Embeddings:**\n",
        "- CharCNN for OOV word handling\n",
        "- Convolutions with kernel sizes [2, 3, 4]\n",
        "- 50-dimensional character-level features\n",
        "- Fused with word embeddings (GloVe 300d)\n",
        "\n",
        "**Fusion:**\n",
        "- Gated fusion mechanism (learnable title vs abstract importance)\n",
        "- Layer normalization\n",
        "\n",
        "**Classifier:**\n",
        "- **3-layer deep classifier** [1760 → 512 → 256 → 3]\n",
        "- LayerNorm + Dropout(0.6) between layers\n",
        "\n",
        "## Advanced Optimizations\n",
        "\n",
        "**Embeddings:**\n",
        "- **GloVe 300d pretrained** (53.8% coverage)\n",
        "- **Character-level CNN** for OOV words (46.2% vocabulary)\n",
        "- Trainable for domain adaptation\n",
        "\n",
        "**Regularization:**\n",
        "- Uniform dropout: 0.6\n",
        "- Strong weight decay: 1e-3\n",
        "- **EDA data augmentation** (50% probability)\n",
        "- **Mixup augmentation** (30% batches, feature space)\n",
        "- Label smoothing: 0.15\n",
        "\n",
        "**Training Optimizations:**\n",
        "- **Gradient accumulation** (4 steps, effective batch: 128)\n",
        "- **Warm-up scheduler** (3 epochs)\n",
        "- **Cosine annealing** learning rate\n",
        "- **SWA (Stochastic Weight Averaging)** from epoch 24\n",
        "- AdamW optimizer with gradient clipping\n",
        "\n",
        "**Class Balancing:**\n",
        "- Class weights: **[1.0, 2.0, 1.8]** for [cs.AI-LG, cs.CL, cs.CV]\n",
        "- CrossEntropyLoss with label smoothing\n",
        "\n",
        "**Expected Performance:**\n",
        "- Single model: 68-73% test accuracy\n",
        "- Ensemble (5 models): 72-77% test accuracy\n",
        "\n",
        "## Improvements Over Baseline (59.33%)\n",
        "\n",
        "| Component | Baseline | Deep Architecture | Impact |\n",
        "|-----------|----------|-------------------|--------|\n",
        "| **LSTM Layers** | 2 | 3 | Deeper semantic understanding |\n",
        "| **LSTM Attention** | 4 heads | 8 heads | Richer pattern capture |\n",
        "| **CNN Architecture** | Vanilla | Dilated residual | Long-range dependencies |\n",
        "| **CNN Blocks** | 3 | 9 (3 kernels × 3 dilations) | More diverse features |\n",
        "| **CNN Attention** | 4 heads | 8 heads | Better feature importance |\n",
        "| **Embeddings** | GloVe only | GloVe + CharCNN | OOV handling |\n",
        "| **Classifier** | 2 layers | 3 layers | Better decision boundary |\n",
        "| **Augmentation** | None → EDA 30% | EDA 50% + Mixup 30% | Stronger regularization |\n",
        "| **Scheduler** | ReduceLR | Warm-up + Cosine | Better convergence |\n",
        "| **Weight Averaging** | None | SWA | Improved generalization |\n",
        "| **Batch Size** | 64 | 128 (grad accum) | More stable gradients |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kElPZcWSXDoV"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch scikit-learn pandas matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1FpC_NXDoV",
        "outputId": "e13a7302-5b33-4bc5-bca4-5a7f79ee6857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uffqkbyzXDoV"
      },
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "Mount your Google Drive to access data files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4MCeEoXDoW",
        "outputId": "799c5219-0caa-4090-eab8-fcba72d73e8e"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = '/content/drive/MyDrive/ArXiv_Project'\n",
        "DATASET_PATH = os.path.join(DATA_DIR, 'arxiv_papers_raw.csv')\n",
        "GLOVE_PATH = os.path.join(DATA_DIR, 'glove.6B.300d.txt')\n",
        "\n",
        "print(f\"\\nChecking files in: {DATA_DIR}\")\n",
        "if os.path.exists(DATASET_PATH):\n",
        "    print(f\"✓ Found: arxiv_papers_raw.csv\")\n",
        "else:\n",
        "    print(f\"✗ Missing: arxiv_papers_raw.csv\")\n",
        "\n",
        "if os.path.exists(GLOVE_PATH):\n",
        "    print(f\"✓ Found: glove.6B.300d.txt\")\n",
        "else:\n",
        "    print(f\"✗ Missing: glove.6B.300d.txt\")\n",
        "\n",
        "if not (os.path.exists(DATASET_PATH) and os.path.exists(GLOVE_PATH)):\n",
        "    print(f\"\\n⚠️  Please upload files to: {DATA_DIR}\")\n",
        "    print(\"Required files:\")\n",
        "    print(\"  - arxiv_papers_raw.csv\")\n",
        "    print(\"  - glove.6B.300d.txt\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "Checking files in: /content/drive/MyDrive/ArXiv_Project\n",
            "✓ Found: arxiv_papers_raw.csv\n",
            "✓ Found: glove.6B.300d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ENaUtdIbXDoW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class CharCNN(nn.Module):\n",
        "    \"\"\"Character-level CNN for OOV words\"\"\"\n",
        "    def __init__(self, char_vocab_size=128, char_embed_dim=25, output_dim=50):\n",
        "        super().__init__()\n",
        "        self.char_embedding = nn.Embedding(char_vocab_size, char_embed_dim, padding_idx=0)\n",
        "\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(char_embed_dim, 50, 2),\n",
        "            nn.Conv1d(char_embed_dim, 75, 3),\n",
        "            nn.Conv1d(char_embed_dim, 75, 4)\n",
        "        ])\n",
        "\n",
        "        self.projection = nn.Linear(200, output_dim)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, char_ids):\n",
        "        # char_ids: (batch, seq_len, max_word_len)\n",
        "        batch_size, seq_len, max_word_len = char_ids.size()\n",
        "        char_ids_flat = char_ids.view(-1, max_word_len)\n",
        "\n",
        "        char_embeds = self.char_embedding(char_ids_flat)\n",
        "        char_embeds = char_embeds.transpose(1, 2)\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv in self.convs:\n",
        "            conv_out = F.relu(conv(char_embeds))\n",
        "            pooled = F.max_pool1d(conv_out, conv_out.size(2)).squeeze(2)\n",
        "            conv_outputs.append(pooled)\n",
        "\n",
        "        concat = torch.cat(conv_outputs, dim=1)\n",
        "        concat = self.dropout(concat)\n",
        "        output = self.projection(concat)\n",
        "\n",
        "        return output.view(batch_size, seq_len, -1)\n",
        "\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    \"\"\"Multi-head self-attention over LSTM outputs\"\"\"\n",
        "    def __init__(self, hidden_dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        assert hidden_dim % num_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_dim // num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.k_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.v_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.out_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        Q = self.q_linear(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K = self.k_linear(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = self.v_linear(x).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
        "\n",
        "        if mask is not None:\n",
        "            mask = mask.unsqueeze(1).unsqueeze(2)\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        attention_weights = F.softmax(scores, dim=-1)\n",
        "        attention_weights = self.dropout(attention_weights)\n",
        "\n",
        "        context = torch.matmul(attention_weights, V)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_dim)\n",
        "\n",
        "        output = self.out_linear(context)\n",
        "        output = self.layer_norm(output + x)\n",
        "\n",
        "        pooled = torch.mean(output, dim=1)\n",
        "\n",
        "        return pooled, attention_weights.mean(dim=1)\n",
        "\n",
        "\n",
        "class MultiHeadGlobalAttention(nn.Module):\n",
        "    \"\"\"Multi-head global attention over CNN features\"\"\"\n",
        "    def __init__(self, feature_dim, num_heads=8):\n",
        "        super().__init__()\n",
        "        assert feature_dim % num_heads == 0\n",
        "\n",
        "        self.feature_dim = feature_dim\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.attention = nn.Linear(feature_dim, num_heads)\n",
        "        self.projection = nn.Linear(feature_dim, feature_dim)\n",
        "        self.layer_norm = nn.LayerNorm(feature_dim)\n",
        "\n",
        "    def forward(self, cnn_features):\n",
        "        batch_size, channels, seq_len = cnn_features.size()\n",
        "        features_t = cnn_features.transpose(1, 2)\n",
        "\n",
        "        scores = self.attention(features_t)\n",
        "        attention_weights = F.softmax(scores, dim=1)\n",
        "\n",
        "        head_outputs = []\n",
        "        for h in range(self.num_heads):\n",
        "            head_weights = attention_weights[:, :, h:h+1]\n",
        "            head_context = torch.sum(features_t * head_weights, dim=1)\n",
        "            head_outputs.append(head_context)\n",
        "\n",
        "        context = torch.stack(head_outputs, dim=1).mean(dim=1)\n",
        "        output = self.projection(context)\n",
        "        output = self.layer_norm(output + context)\n",
        "\n",
        "        return output, attention_weights.mean(dim=2)\n",
        "\n",
        "\n",
        "class GatedFusion(nn.Module):\n",
        "    \"\"\"Gated fusion mechanism for title and abstract\"\"\"\n",
        "    def __init__(self, title_dim, abstract_dim):\n",
        "        super().__init__()\n",
        "        combined_dim = title_dim + abstract_dim\n",
        "\n",
        "        self.title_gate = nn.Sequential(\n",
        "            nn.Linear(combined_dim, title_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.abstract_gate = nn.Sequential(\n",
        "            nn.Linear(combined_dim, abstract_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.layer_norm = nn.LayerNorm(combined_dim)\n",
        "\n",
        "    def forward(self, title_repr, abstract_repr):\n",
        "        combined = torch.cat([title_repr, abstract_repr], dim=1)\n",
        "\n",
        "        title_gate = self.title_gate(combined)\n",
        "        abstract_gate = self.abstract_gate(combined)\n",
        "\n",
        "        gated_title = title_repr * title_gate\n",
        "        gated_abstract = abstract_repr * abstract_gate\n",
        "\n",
        "        fused = torch.cat([gated_title, gated_abstract], dim=1)\n",
        "        fused = self.layer_norm(fused)\n",
        "\n",
        "        fusion_weights = torch.stack([title_gate.mean(dim=1), abstract_gate.mean(dim=1)], dim=1)\n",
        "\n",
        "        return fused, fusion_weights\n",
        "\n",
        "\n",
        "class DilatedResidualCNNBlock(nn.Module):\n",
        "    \"\"\"Dilated residual CNN block for long-range dependencies\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, dropout=0.3):\n",
        "        super().__init__()\n",
        "        padding = (kernel_size - 1) * dilation // 2\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size, padding=padding, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "\n",
        "        self.skip = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.skip(x)\n",
        "\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        min_len = min(out.size(2), identity.size(2))\n",
        "        out = out[:, :, :min_len]\n",
        "        identity = identity[:, :, :min_len]\n",
        "\n",
        "        out = F.relu(out + identity)\n",
        "        return out\n",
        "\n",
        "\n",
        "class DeepHybridCNNLSTM(nn.Module):\n",
        "    \"\"\"Deep hybrid architecture with character embeddings\"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=300, num_filters=160, kernel_sizes=[3,4,5],\n",
        "                 lstm_hidden=160, num_classes=3, dropout=0.6, pretrained_embeddings=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Word embeddings\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        if pretrained_embeddings is not None:\n",
        "            self.word_embedding.weight.data.copy_(pretrained_embeddings)\n",
        "            self.word_embedding.weight.requires_grad = True\n",
        "\n",
        "        # Character embeddings for OOV handling\n",
        "        self.char_cnn = CharCNN(output_dim=50)\n",
        "        self.embed_fusion = nn.Linear(embed_dim + 50, embed_dim)\n",
        "\n",
        "        self.embed_dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Deeper dilated residual CNN blocks\n",
        "        self.cnn_blocks = nn.ModuleList()\n",
        "        dilations = [1, 2, 4]\n",
        "        for k in kernel_sizes:\n",
        "            for d in dilations:\n",
        "                self.cnn_blocks.append(\n",
        "                    DilatedResidualCNNBlock(embed_dim, num_filters, k, dilation=d, dropout=dropout*0.5)\n",
        "                )\n",
        "        total_filters = num_filters * len(kernel_sizes) * len(dilations)\n",
        "\n",
        "        # Multi-head global attention (8 heads)\n",
        "        self.cnn_attention = MultiHeadGlobalAttention(total_filters, num_heads=8)\n",
        "\n",
        "        # Deeper BiLSTM (3 layers)\n",
        "        self.lstm = nn.LSTM(embed_dim, lstm_hidden, num_layers=3, batch_first=True,\n",
        "                           bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
        "\n",
        "        # Multi-head self-attention (8 heads)\n",
        "        self.lstm_attention = MultiHeadSelfAttention(lstm_hidden * 2, num_heads=8)\n",
        "\n",
        "        # Gated fusion\n",
        "        self.fusion = GatedFusion(lstm_hidden * 2, total_filters)\n",
        "\n",
        "        # Deeper classifier (3 layers)\n",
        "        fused_dim = lstm_hidden * 2 + total_filters\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.LayerNorm(fused_dim),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(fused_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(512),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.LayerNorm(256),\n",
        "            nn.Dropout(dropout * 0.8),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.LSTM):\n",
        "                for name, param in m.named_parameters():\n",
        "                    if 'weight_ih' in name:\n",
        "                        nn.init.xavier_uniform_(param.data)\n",
        "                    elif 'weight_hh' in name:\n",
        "                        nn.init.orthogonal_(param.data)\n",
        "                    elif 'bias' in name:\n",
        "                        nn.init.zeros_(param.data)\n",
        "\n",
        "    def forward(self, title_ids, abstract_ids, title_mask=None, char_ids=None):\n",
        "        # Word embeddings\n",
        "        title_word_embed = self.word_embedding(title_ids)\n",
        "        abstract_word_embed = self.word_embedding(abstract_ids)\n",
        "\n",
        "        # Character embeddings (if provided)\n",
        "        if char_ids is not None:\n",
        "            title_char_embed = self.char_cnn(char_ids['title'])\n",
        "            abstract_char_embed = self.char_cnn(char_ids['abstract'])\n",
        "\n",
        "            title_embed = self.embed_fusion(torch.cat([title_word_embed, title_char_embed], dim=-1))\n",
        "            abstract_embed = self.embed_fusion(torch.cat([abstract_word_embed, abstract_char_embed], dim=-1))\n",
        "        else:\n",
        "            title_embed = title_word_embed\n",
        "            abstract_embed = abstract_word_embed\n",
        "\n",
        "        title_embed = self.embed_dropout(title_embed)\n",
        "        abstract_embed = self.embed_dropout(abstract_embed)\n",
        "\n",
        "        # Title: Deeper BiLSTM + 8-head attention\n",
        "        lstm_out, _ = self.lstm(title_embed)\n",
        "        title_repr, title_attn = self.lstm_attention(lstm_out, title_mask)\n",
        "\n",
        "        # Abstract: Dilated residual CNN + 8-head attention\n",
        "        abstract_embed = abstract_embed.transpose(1, 2)\n",
        "\n",
        "        cnn_outputs = []\n",
        "        for cnn_block in self.cnn_blocks:\n",
        "            cnn_out = cnn_block(abstract_embed)\n",
        "            cnn_outputs.append(cnn_out)\n",
        "\n",
        "        min_len = min(x.size(2) for x in cnn_outputs)\n",
        "        cnn_outputs = [x[:, :, :min_len] for x in cnn_outputs]\n",
        "\n",
        "        cnn_features = torch.cat(cnn_outputs, dim=1)\n",
        "        abstract_repr, abstract_attn = self.cnn_attention(cnn_features)\n",
        "\n",
        "        # Gated fusion\n",
        "        fused_repr, fusion_weights = self.fusion(title_repr, abstract_repr)\n",
        "\n",
        "        # Deep classifier\n",
        "        logits = self.classifier(fused_repr)\n",
        "\n",
        "        attention_maps = {\n",
        "            'title_attention': title_attn,\n",
        "            'abstract_attention': abstract_attn,\n",
        "            'fusion_weights': fusion_weights\n",
        "        }\n",
        "        return logits, attention_maps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC94tYQgXDoW"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SKNLhJZyXDoW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "class EDA:\n",
        "    \"\"\"Easy Data Augmentation for text\"\"\"\n",
        "    @staticmethod\n",
        "    def synonym_replacement(words, n):\n",
        "        new_words = words.copy()\n",
        "        random_indices = random.sample(range(len(words)), min(n, len(words)))\n",
        "        for idx in random_indices:\n",
        "            synonyms = {\n",
        "                'network': ['model', 'system', 'architecture'],\n",
        "                'method': ['approach', 'technique', 'algorithm'],\n",
        "                'learning': ['training', 'optimization'],\n",
        "                'performance': ['accuracy', 'results', 'effectiveness'],\n",
        "                'data': ['dataset', 'information', 'samples'],\n",
        "                'model': ['network', 'system', 'framework'],\n",
        "                'task': ['problem', 'challenge', 'objective'],\n",
        "            }\n",
        "            word = words[idx].lower()\n",
        "            if word in synonyms:\n",
        "                new_words[idx] = random.choice(synonyms[word])\n",
        "        return new_words\n",
        "\n",
        "    @staticmethod\n",
        "    def random_swap(words, n):\n",
        "        new_words = words.copy()\n",
        "        for _ in range(n):\n",
        "            if len(new_words) >= 2:\n",
        "                idx1, idx2 = random.sample(range(len(new_words)), 2)\n",
        "                new_words[idx1], new_words[idx2] = new_words[idx2], new_words[idx1]\n",
        "        return new_words\n",
        "\n",
        "    @staticmethod\n",
        "    def random_deletion(words, p=0.1):\n",
        "        if len(words) == 1:\n",
        "            return words\n",
        "        new_words = [word for word in words if random.random() > p]\n",
        "        return new_words if len(new_words) > 0 else [random.choice(words)]\n",
        "\n",
        "    @staticmethod\n",
        "    def augment(text, alpha=0.15):\n",
        "        words = text.split()\n",
        "        n = max(1, int(alpha * len(words)))\n",
        "\n",
        "        aug_type = random.choice(['sr', 'rs', 'rd'])\n",
        "        if aug_type == 'sr':\n",
        "            words = EDA.synonym_replacement(words, n)\n",
        "        elif aug_type == 'rs':\n",
        "            words = EDA.random_swap(words, n)\n",
        "        else:\n",
        "            words = EDA.random_deletion(words, p=alpha)\n",
        "\n",
        "        return ' '.join(words)\n",
        "\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self, max_vocab_size=50000, min_freq=2):\n",
        "        self.max_vocab_size = max_vocab_size\n",
        "        self.min_freq = min_freq\n",
        "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
        "        self.word_counts = Counter()\n",
        "\n",
        "    def build_vocab(self, texts):\n",
        "        for text in texts:\n",
        "            words = self.tokenize(text)\n",
        "            self.word_counts.update(words)\n",
        "        filtered_words = [word for word, count in self.word_counts.most_common() if count >= self.min_freq][:self.max_vocab_size - 2]\n",
        "        for idx, word in enumerate(filtered_words, start=2):\n",
        "            self.word2idx[word] = idx\n",
        "            self.idx2word[idx] = word\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenize(text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z0-9\\s\\-]', ' ', text)\n",
        "        return [w.strip() for w in text.split() if w.strip()]\n",
        "\n",
        "    def encode(self, text, max_len=None):\n",
        "        words = self.tokenize(text)\n",
        "        if max_len:\n",
        "            words = words[:max_len]\n",
        "        return [self.word2idx.get(word, 1) for word in words]\n",
        "\n",
        "    def encode_chars(self, text, max_len=None, max_word_len=20):\n",
        "        \"\"\"Encode text as character IDs for each word\"\"\"\n",
        "        words = self.tokenize(text)\n",
        "        if max_len:\n",
        "            words = words[:max_len]\n",
        "\n",
        "        char_ids = []\n",
        "        for word in words:\n",
        "            word_chars = [min(ord(c), 127) for c in word[:max_word_len]]\n",
        "            word_chars += [0] * (max_word_len - len(word_chars))\n",
        "            char_ids.append(word_chars)\n",
        "\n",
        "        return char_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n",
        "\n",
        "\n",
        "def load_glove_embeddings(vocab, glove_path, embed_dim=300):\n",
        "    embeddings = np.random.randn(len(vocab), embed_dim) * 0.01\n",
        "    embeddings[0] = np.zeros(embed_dim)\n",
        "\n",
        "    found = 0\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in tqdm(f, desc='Loading GloVe'):\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != embed_dim + 1:\n",
        "                continue\n",
        "            word = parts[0]\n",
        "            if word in vocab.word2idx:\n",
        "                idx = vocab.word2idx[word]\n",
        "                try:\n",
        "                    embeddings[idx] = np.array([float(x) for x in parts[1:]])\n",
        "                    found += 1\n",
        "                except (ValueError, IndexError):\n",
        "                    continue\n",
        "\n",
        "    print(f\"Loaded {found}/{len(vocab)} embeddings ({found/len(vocab)*100:.1f}%)\")\n",
        "    return torch.FloatTensor(embeddings)\n",
        "\n",
        "\n",
        "class DeepHybridDataset(Dataset):\n",
        "    def __init__(self, titles, abstracts, labels, vocab, max_title_len=30, max_abstract_len=300,\n",
        "                 use_char_embed=True, augment=False):\n",
        "        self.titles = titles\n",
        "        self.abstracts = abstracts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_title_len = max_title_len\n",
        "        self.max_abstract_len = max_abstract_len\n",
        "        self.use_char_embed = use_char_embed\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        title = self.titles[idx]\n",
        "        abstract = self.abstracts[idx]\n",
        "\n",
        "        # Apply augmentation (50% probability for stronger regularization)\n",
        "        if self.augment and random.random() < 0.5:\n",
        "            abstract = EDA.augment(abstract, alpha=0.15)\n",
        "\n",
        "        title_ids = self.vocab.encode(title, self.max_title_len)\n",
        "        title_len = len(title_ids)\n",
        "        title_ids += [0] * (self.max_title_len - title_len)\n",
        "\n",
        "        abstract_ids = self.vocab.encode(abstract, self.max_abstract_len)\n",
        "        abstract_len = len(abstract_ids)\n",
        "        abstract_ids += [0] * (self.max_abstract_len - abstract_len)\n",
        "\n",
        "        title_mask = [1] * title_len + [0] * (self.max_title_len - title_len)\n",
        "\n",
        "        result = {\n",
        "            'title_ids': torch.tensor(title_ids, dtype=torch.long),\n",
        "            'abstract_ids': torch.tensor(abstract_ids, dtype=torch.long),\n",
        "            'title_mask': torch.tensor(title_mask, dtype=torch.float),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "        # Character-level IDs for OOV handling\n",
        "        if self.use_char_embed:\n",
        "            title_char_ids = self.vocab.encode_chars(title, self.max_title_len)\n",
        "            abstract_char_ids = self.vocab.encode_chars(abstract, self.max_abstract_len)\n",
        "\n",
        "            # Pad to max lengths\n",
        "            while len(title_char_ids) < self.max_title_len:\n",
        "                title_char_ids.append([0] * 20)\n",
        "            while len(abstract_char_ids) < self.max_abstract_len:\n",
        "                abstract_char_ids.append([0] * 20)\n",
        "\n",
        "            result['char_ids'] = {\n",
        "                'title': torch.tensor(title_char_ids, dtype=torch.long),\n",
        "                'abstract': torch.tensor(abstract_char_ids, dtype=torch.long)\n",
        "            }\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAS1pFjHXDoW"
      },
      "source": [
        "## Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZs1YRmtXDoW",
        "outputId": "1b71d338-5241-4990-bb48-cd239b5a5b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samples: 12000\n",
            "category\n",
            "cs.AI-LG    6000\n",
            "cs.CV       3000\n",
            "cs.CL       3000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Vocab size: 37760\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading GloVe: 400000it [00:16, 24570.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 20320/37760 embeddings (53.8%)\n",
            "\n",
            "Train: 8399 (augmentation + char embeddings)\n",
            "Val: 1801 | Test: 1800\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(DATASET_PATH)\n",
        "df['category'] = df['category'].replace({'cs.AI': 'cs.AI-LG', 'cs.LG': 'cs.AI-LG'})\n",
        "\n",
        "print(f\"Samples: {len(df)}\")\n",
        "print(df['category'].value_counts())\n",
        "\n",
        "vocab = Vocabulary(max_vocab_size=50000, min_freq=2)\n",
        "all_texts = df['title'].tolist() + df['abstract'].tolist()\n",
        "vocab.build_vocab(all_texts)\n",
        "print(f\"\\nVocab size: {len(vocab)}\")\n",
        "\n",
        "# Use GloVe embeddings\n",
        "pretrained_embeddings = load_glove_embeddings(vocab, GLOVE_PATH, embed_dim=300)\n",
        "\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(df['category'])\n",
        "\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    df[['title', 'abstract']].values, labels, test_size=0.15, random_state=42, stratify=labels\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.15/(1-0.15), random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# Create datasets with character embeddings and augmentation\n",
        "train_ds = DeepHybridDataset(X_train[:,0], X_train[:,1], y_train, vocab, use_char_embed=True, augment=True)\n",
        "val_ds = DeepHybridDataset(X_val[:,0], X_val[:,1], y_val, vocab, use_char_embed=True, augment=False)\n",
        "test_ds = DeepHybridDataset(X_test[:,0], X_test[:,1], y_test, vocab, use_char_embed=True, augment=False)\n",
        "\n",
        "print(f\"\\nTrain: {len(train_ds)} (augmentation + char embeddings)\")\n",
        "print(f\"Val: {len(val_ds)} | Test: {len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOfpWNxoXDoX"
      },
      "source": [
        "## Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EXetoWPIXDoX"
      },
      "outputs": [],
      "source": [
        "def mixup_data(x, y, alpha=0.2):\n",
        "    \"\"\"Mixup augmentation in feature space\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device, use_mixup=True, mixup_alpha=0.2):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    for batch in tqdm(loader, desc='Train'):\n",
        "        title_ids = batch['title_ids'].to(device)\n",
        "        abstract_ids = batch['abstract_ids'].to(device)\n",
        "        title_mask = batch['title_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # Get character IDs if available\n",
        "        char_ids = None\n",
        "        if 'char_ids' in batch:\n",
        "            char_ids = {\n",
        "                'title': batch['char_ids']['title'].to(device),\n",
        "                'abstract': batch['char_ids']['abstract'].to(device)\n",
        "            }\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get embeddings (for Mixup in feature space)\n",
        "        logits, _ = model(title_ids, abstract_ids, title_mask, char_ids)\n",
        "\n",
        "        # Apply Mixup (30% of batches)\n",
        "        if use_mixup and random.random() < 0.3:\n",
        "            # Get embeddings by extracting from intermediate layer\n",
        "            with torch.no_grad():\n",
        "                # Re-run to get fused features before classifier\n",
        "                model.eval()\n",
        "                title_embed = model.word_embedding(title_ids)\n",
        "                abstract_embed = model.word_embedding(abstract_ids)\n",
        "\n",
        "                if char_ids is not None:\n",
        "                    title_char_embed = model.char_cnn(char_ids['title'])\n",
        "                    abstract_char_embed = model.char_cnn(char_ids['abstract'])\n",
        "                    title_embed = model.embed_fusion(torch.cat([title_embed, title_char_embed], dim=-1))\n",
        "                    abstract_embed = model.embed_fusion(torch.cat([abstract_embed, abstract_char_embed], dim=-1))\n",
        "\n",
        "                title_embed = model.embed_dropout(title_embed)\n",
        "                abstract_embed = model.embed_dropout(abstract_embed)\n",
        "\n",
        "                # Get LSTM output\n",
        "                lstm_out, _ = model.lstm(title_embed)\n",
        "                title_repr, _ = model.lstm_attention(lstm_out, title_mask)\n",
        "\n",
        "                # Get CNN output\n",
        "                abstract_embed_t = abstract_embed.transpose(1, 2)\n",
        "                cnn_outputs = []\n",
        "                for cnn_block in model.cnn_blocks:\n",
        "                    cnn_out = cnn_block(abstract_embed_t)\n",
        "                    cnn_outputs.append(cnn_out)\n",
        "                min_len = min(x.size(2) for x in cnn_outputs)\n",
        "                cnn_outputs = [x[:, :, :min_len] for x in cnn_outputs]\n",
        "                cnn_features = torch.cat(cnn_outputs, dim=1)\n",
        "                abstract_repr, _ = model.cnn_attention(cnn_features)\n",
        "\n",
        "                # Fuse\n",
        "                fused_repr, _ = model.fusion(title_repr, abstract_repr)\n",
        "\n",
        "            model.train()\n",
        "            # Apply Mixup to fused features\n",
        "            mixed_fused, labels_a, labels_b, lam = mixup_data(fused_repr, labels, alpha=mixup_alpha)\n",
        "\n",
        "            # Pass through classifier\n",
        "            logits = model.classifier(mixed_fused)\n",
        "\n",
        "            # Mixup loss\n",
        "            loss = lam * criterion(logits, labels_a) + (1 - lam) * criterion(logits, labels_b)\n",
        "        else:\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return total_loss / len(loader), accuracy_score(all_labels, all_preds)\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Val'):\n",
        "            title_ids = batch['title_ids'].to(device)\n",
        "            abstract_ids = batch['abstract_ids'].to(device)\n",
        "            title_mask = batch['title_mask'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            # Get character IDs if available\n",
        "            char_ids = None\n",
        "            if 'char_ids' in batch:\n",
        "                char_ids = {\n",
        "                    'title': batch['char_ids']['title'].to(device),\n",
        "                    'abstract': batch['char_ids']['abstract'].to(device)\n",
        "                }\n",
        "\n",
        "            logits, _ = model(title_ids, abstract_ids, title_mask, char_ids)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    return total_loss / len(loader), acc, f1, all_preds, all_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYTb33XHXDoX"
      },
      "source": [
        "## Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BZPpHZfXDoX",
        "outputId": "512bf7ab-d128-4df7-9a18-58b7fe43e158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters: 23,021,970\n",
            "Architecture: DeepHybridCNNLSTM\n",
            "  - LSTM: 3 layers, 160 hidden, bidirectional\n",
            "  - CNN: 9 dilated residual blocks (3 kernels × 3 dilations)\n",
            "  - Attention: 8 heads (LSTM + CNN)\n",
            "  - Character embeddings: Enabled\n",
            "  - Classifier: 3 layers [1760→512→256→3]\n",
            "\n",
            "Deep Architecture Configuration:\n",
            "  Embeddings: GloVe + Character-level CNN\n",
            "  Class weights: [1.0, 2.0, 1.8]\n",
            "  Loss: CrossEntropyLoss + label smoothing (0.15)\n",
            "  Dropout: 0.6\n",
            "  Batch size: 32 (effective: 128)\n",
            "  Scheduler: Warm-up (3 epochs) + Cosine annealing\n",
            "  Regularization: Mixup (30%), EDA (50%), Dropout, Weight decay\n",
            "\n",
            "Expected: 72-77% accuracy (with ensemble)\n",
            "Single model target: 68-73%\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 32  # Reduced for gradient accumulation (effective: 128)\n",
        "EPOCHS = 40\n",
        "LR = 0.001\n",
        "WARMUP_EPOCHS = 3\n",
        "DROPOUT = 0.6\n",
        "CLASS_WEIGHTS = [1.0, 2.0, 1.8]  # Fixed cs.CL weight back to 2.0\n",
        "LABEL_SMOOTHING = 0.15  # Increased from 0.1\n",
        "PATIENCE = 10  # Increased patience\n",
        "GRAD_ACCUM_STEPS = 4  # Effective batch size: 32 * 4 = 128\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Use DeepHybridCNNLSTM with character embeddings\n",
        "model = DeepHybridCNNLSTM(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=300,\n",
        "    num_filters=160,  # Increased capacity for deep model\n",
        "    kernel_sizes=[3,4,5],\n",
        "    lstm_hidden=160,\n",
        "    num_classes=3,\n",
        "    dropout=DROPOUT,\n",
        "    pretrained_embeddings=pretrained_embeddings\n",
        ").to(device)\n",
        "\n",
        "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Architecture: DeepHybridCNNLSTM\")\n",
        "print(f\"  - LSTM: 3 layers, 160 hidden, bidirectional\")\n",
        "print(f\"  - CNN: 9 dilated residual blocks (3 kernels × 3 dilations)\")\n",
        "print(f\"  - Attention: 8 heads (LSTM + CNN)\")\n",
        "print(f\"  - Character embeddings: Enabled\")\n",
        "print(f\"  - Classifier: 3 layers [1760→512→256→3]\")\n",
        "\n",
        "# Use CrossEntropyLoss with stronger label smoothing\n",
        "class_weights = torch.FloatTensor(CLASS_WEIGHTS).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=LABEL_SMOOTHING)\n",
        "\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-3, betas=(0.9, 0.999))\n",
        "\n",
        "# Warm-up + Cosine Annealing scheduler\n",
        "def get_lr_lambda(epoch):\n",
        "    if epoch < WARMUP_EPOCHS:\n",
        "        # Linear warm-up\n",
        "        return (epoch + 1) / WARMUP_EPOCHS\n",
        "    else:\n",
        "        # Cosine annealing\n",
        "        progress = (epoch - WARMUP_EPOCHS) / (EPOCHS - WARMUP_EPOCHS)\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * progress))\n",
        "\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda)\n",
        "\n",
        "print(f\"\\nDeep Architecture Configuration:\")\n",
        "print(f\"  Embeddings: GloVe + Character-level CNN\")\n",
        "print(f\"  Class weights: {CLASS_WEIGHTS}\")\n",
        "print(f\"  Loss: CrossEntropyLoss + label smoothing ({LABEL_SMOOTHING})\")\n",
        "print(f\"  Dropout: {DROPOUT}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE} (effective: {BATCH_SIZE * GRAD_ACCUM_STEPS})\")\n",
        "print(f\"  Scheduler: Warm-up ({WARMUP_EPOCHS} epochs) + Cosine annealing\")\n",
        "print(f\"  Regularization: Mixup (30%), EDA (50%), Dropout, Weight decay\")\n",
        "print(f\"\\nExpected: 72-77% accuracy (with ensemble)\")\n",
        "print(f\"Single model target: 68-73%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaF7CMbiXDoX"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LooeJmbXDoX",
        "outputId": "32e3f40b-b1a6-44fc-9d01-30f165fee14d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration:\n",
            "  Gradient accumulation: 4 steps\n",
            "  Effective batch size: 128\n",
            "  SWA start: epoch 24\n",
            "  Mixup: Enabled (30% of batches)\n",
            "\n",
            "Starting training...\n",
            "\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:54<00:00,  4.83it/s]\n",
            "Val: 100%|██████████| 57/57 [00:05<00:00, 10.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3359 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0860\n",
            "LR: 0.000333\n",
            "✓ Best: 0.2499\n",
            "\n",
            "Epoch 2/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:51<00:00,  5.11it/s]\n",
            "Val: 100%|██████████| 57/57 [00:04<00:00, 12.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3173 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0674\n",
            "LR: 0.000667\n",
            "\n",
            "Epoch 3/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:52<00:00,  5.03it/s]\n",
            "Val: 100%|██████████| 57/57 [00:04<00:00, 11.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3174 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0676\n",
            "LR: 0.001000\n",
            "\n",
            "Epoch 4/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:52<00:00,  5.00it/s]\n",
            "Val: 100%|██████████| 57/57 [00:05<00:00, 10.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3229 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0730\n",
            "LR: 0.001000\n",
            "\n",
            "Epoch 5/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:52<00:00,  5.02it/s]\n",
            "Val: 100%|██████████| 57/57 [00:04<00:00, 12.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3038 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0540\n",
            "LR: 0.000998\n",
            "\n",
            "Epoch 6/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:54<00:00,  4.86it/s]\n",
            "Val: 100%|██████████| 57/57 [00:05<00:00, 10.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3088 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0590\n",
            "LR: 0.000993\n",
            "\n",
            "Epoch 7/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:53<00:00,  4.90it/s]\n",
            "Val: 100%|██████████| 57/57 [00:04<00:00, 12.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3144 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0646\n",
            "LR: 0.000984\n",
            "\n",
            "Epoch 8/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:54<00:00,  4.79it/s]\n",
            "Val: 100%|██████████| 57/57 [00:05<00:00, 10.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3192 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0693\n",
            "LR: 0.000971\n",
            "\n",
            "Epoch 9/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:54<00:00,  4.83it/s]\n",
            "Val: 100%|██████████| 57/57 [00:04<00:00, 12.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3040 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0541\n",
            "LR: 0.000956\n",
            "\n",
            "Epoch 10/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:54<00:00,  4.86it/s]\n",
            "Val: 100%|██████████| 57/57 [00:05<00:00, 10.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.3063 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0565\n",
            "LR: 0.000937\n",
            "\n",
            "Epoch 11/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train: 100%|██████████| 263/263 [00:53<00:00,  4.93it/s]\n",
            "Val: 100%|██████████| 57/57 [00:04<00:00, 12.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.2944 | Val: 0.2499 | F1: 0.0999 | Gap: 0.0446\n",
            "LR: 0.000914\n",
            "Early stop (patience: 10)\n",
            "\n",
            "=== Using Best Checkpoint ===\n",
            "Best validation accuracy: 0.2499\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'lr': []}\n",
        "best_val_acc = 0\n",
        "best_model_state = None\n",
        "patience_counter = 0\n",
        "\n",
        "# SWA (Stochastic Weight Averaging) - start after 60% of training\n",
        "swa_start_epoch = int(EPOCHS * 0.6)\n",
        "swa_model = optim.swa_utils.AveragedModel(model)\n",
        "swa_scheduler = optim.swa_utils.SWALR(optimizer, swa_lr=0.0005)\n",
        "\n",
        "print(f\"Training configuration:\")\n",
        "print(f\"  Gradient accumulation: {GRAD_ACCUM_STEPS} steps\")\n",
        "print(f\"  Effective batch size: {BATCH_SIZE * GRAD_ACCUM_STEPS}\")\n",
        "print(f\"  SWA start: epoch {swa_start_epoch}\")\n",
        "print(f\"  Mixup: Enabled (30% of batches)\")\n",
        "print(f\"\\nStarting training...\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Training with gradient accumulation\n",
        "    for i, batch in enumerate(tqdm(train_loader, desc='Train')):\n",
        "        title_ids = batch['title_ids'].to(device)\n",
        "        abstract_ids = batch['abstract_ids'].to(device)\n",
        "        title_mask = batch['title_mask'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        # Get character IDs\n",
        "        char_ids = {\n",
        "            'title': batch['char_ids']['title'].to(device),\n",
        "            'abstract': batch['char_ids']['abstract'].to(device)\n",
        "        }\n",
        "\n",
        "        # Forward pass\n",
        "        logits, _ = model(title_ids, abstract_ids, title_mask, char_ids)\n",
        "\n",
        "        # Apply Mixup (30% of batches)\n",
        "        if random.random() < 0.3:\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                title_embed = model.word_embedding(title_ids)\n",
        "                abstract_embed = model.word_embedding(abstract_ids)\n",
        "\n",
        "                title_char_embed = model.char_cnn(char_ids['title'])\n",
        "                abstract_char_embed = model.char_cnn(char_ids['abstract'])\n",
        "                title_embed = model.embed_fusion(torch.cat([title_embed, title_char_embed], dim=-1))\n",
        "                abstract_embed = model.embed_fusion(torch.cat([abstract_embed, abstract_char_embed], dim=-1))\n",
        "\n",
        "                title_embed = model.embed_dropout(title_embed)\n",
        "                abstract_embed = model.embed_dropout(abstract_embed)\n",
        "\n",
        "                lstm_out, _ = model.lstm(title_embed)\n",
        "                title_repr, _ = model.lstm_attention(lstm_out, title_mask)\n",
        "\n",
        "                abstract_embed_t = abstract_embed.transpose(1, 2)\n",
        "                cnn_outputs = []\n",
        "                for cnn_block in model.cnn_blocks:\n",
        "                    cnn_out = cnn_block(abstract_embed_t)\n",
        "                    cnn_outputs.append(cnn_out)\n",
        "                min_len = min(x.size(2) for x in cnn_outputs)\n",
        "                cnn_outputs = [x[:, :, :min_len] for x in cnn_outputs]\n",
        "                cnn_features = torch.cat(cnn_outputs, dim=1)\n",
        "                abstract_repr, _ = model.cnn_attention(cnn_features)\n",
        "\n",
        "                fused_repr, _ = model.fusion(title_repr, abstract_repr)\n",
        "\n",
        "            model.train()\n",
        "            mixed_fused, labels_a, labels_b, lam = mixup_data(fused_repr, labels, alpha=0.2)\n",
        "            logits = model.classifier(mixed_fused)\n",
        "            loss = lam * criterion(logits, labels_a) + (1 - lam) * criterion(logits, labels_b)\n",
        "        else:\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        # Gradient accumulation\n",
        "        loss = loss / GRAD_ACCUM_STEPS\n",
        "        loss.backward()\n",
        "\n",
        "        if (i + 1) % GRAD_ACCUM_STEPS == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * GRAD_ACCUM_STEPS\n",
        "        all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    train_acc = accuracy_score(all_labels, all_preds)\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_f1'].append(val_f1)\n",
        "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    print(f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | F1: {val_f1:.4f} | Gap: {abs(train_acc-val_acc):.4f}\")\n",
        "    print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    # Update learning rate\n",
        "    if epoch >= swa_start_epoch:\n",
        "        swa_model.update_parameters(model)\n",
        "        swa_scheduler.step()\n",
        "        print(f\"SWA: Model updated (epoch {epoch+1})\")\n",
        "    else:\n",
        "        scheduler.step()\n",
        "\n",
        "    # Early stopping based on validation accuracy\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_state = model.state_dict().copy()\n",
        "        patience_counter = 0\n",
        "        print(f\"✓ Best: {val_acc:.4f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= PATIENCE:\n",
        "            print(f\"Early stop (patience: {PATIENCE})\")\n",
        "            break\n",
        "\n",
        "# Load best model or SWA model\n",
        "if epoch >= swa_start_epoch:\n",
        "    print(f\"\\n=== Using SWA Model ===\")\n",
        "    torch.optim.swa_utils.update_bn(train_loader, swa_model, device)\n",
        "    model = swa_model.module\n",
        "else:\n",
        "    print(f\"\\n=== Using Best Checkpoint ===\")\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "print(f\"Best validation accuracy: {best_val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icIfK-RRXDoX"
      },
      "source": [
        "## Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1eedEA5XDoX",
        "outputId": "ebc1683b-0b64-44d1-91f5-3304cfc98474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Val: 100%|██████████| 57/57 [00:05<00:00, 10.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.2500 (25.00%)\n",
            "Test F1: 0.1000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    cs.AI-LG     0.0000    0.0000    0.0000       900\n",
            "       cs.CL     0.2500    1.0000    0.4000       450\n",
            "       cs.CV     0.0000    0.0000    0.0000       450\n",
            "\n",
            "    accuracy                         0.2500      1800\n",
            "   macro avg     0.0833    0.3333    0.1333      1800\n",
            "weighted avg     0.0625    0.2500    0.1000      1800\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
        "    model, test_loader, criterion, device\n",
        ")\n",
        "\n",
        "print(f\"Test Acc: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "print(f\"Test F1: {test_f1:.4f}\")\n",
        "print(f\"\\n{classification_report(test_labels, test_preds, target_names=le.classes_, digits=4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaLLwl9tXDoX"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "oGgP_8puXDoX",
        "outputId": "fef247a8-b67c-4536-b91a-921c7926e46c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=le.classes_,\n",
        "            yticklabels=le.classes_, ax=axes[0])\n",
        "axes[0].set_title('Confusion Matrix (Counts)')\n",
        "axes[0].set_ylabel('True Label')\n",
        "axes[0].set_xlabel('Predicted Label')\n",
        "\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens', xticklabels=le.classes_,\n",
        "            yticklabels=le.classes_, ax=axes[1])\n",
        "axes[1].set_title('Confusion Matrix (Normalized)')\n",
        "axes[1].set_ylabel('True Label')\n",
        "axes[1].set_xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD1hJnCHXDoX"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDjry9BmXDoX",
        "outputId": "0d92f3cb-abfa-4ee6-9a70-92e2dc37e4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved: hybrid_model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'vocab_size': len(vocab),\n",
        "    'class_names': le.classes_.tolist(),\n",
        "    'num_classes': 3\n",
        "}, 'hybrid_model.pth')\n",
        "\n",
        "print('Model saved: hybrid_model.pth')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
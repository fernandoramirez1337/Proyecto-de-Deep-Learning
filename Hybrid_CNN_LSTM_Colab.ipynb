{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fernandoramirez1337/Proyecto-de-Deep-Learning/blob/claude%2Fimprove-implementation-018rMkv8JP1bb2KNiHNbvF1o/Hybrid_CNN_LSTM_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid CNN-LSTM ArXiv Classification\n",
    "\n",
    "3-class model: cs.AI-LG, cs.CL, cs.CV\n",
    "\n",
    "Architecture:\n",
    "- CNN 1D for abstract feature extraction\n",
    "- Bidirectional LSTM for title processing  \n",
    "- Self-attention over LSTM outputs\n",
    "- Global attention over CNN features\n",
    "- Weighted attention fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch scikit-learn pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Mount Google Drive\n\nMount your Google Drive to access data files"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "source": "from google.colab import drive\nimport os\n\ndrive.mount('/content/drive')\n\nDATA_DIR = '/content/drive/MyDrive/ArXiv_Project'\nDATASET_PATH = os.path.join(DATA_DIR, 'arxiv_papers_raw.csv')\nGLOVE_PATH = os.path.join(DATA_DIR, 'glove.6B.300d.txt')\n\nprint(f\"\\nChecking files in: {DATA_DIR}\")\nif os.path.exists(DATASET_PATH):\n    print(f\"✓ Found: arxiv_papers_raw.csv\")\nelse:\n    print(f\"✗ Missing: arxiv_papers_raw.csv\")\n    \nif os.path.exists(GLOVE_PATH):\n    print(f\"✓ Found: glove.6B.300d.txt\")\nelse:\n    print(f\"✗ Missing: glove.6B.300d.txt\")\n\nif not (os.path.exists(DATASET_PATH) and os.path.exists(GLOVE_PATH)):\n    print(f\"\\n⚠️  Please upload files to: {DATA_DIR}\")\n    print(\"Required files:\")\n    print(\"  - arxiv_papers_raw.csv\")\n    print(\"  - glove.6B.300d.txt\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_output, mask=None):\n",
    "        scores = self.attention(lstm_output).squeeze(-1)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), lstm_output).squeeze(1)\n",
    "        return context, attention_weights\n",
    "\n",
    "\n",
    "class GlobalAttention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, cnn_features):\n",
    "        batch_size, channels, seq_len = cnn_features.size()\n",
    "        features_t = cnn_features.transpose(1, 2)\n",
    "        scores = self.attention(features_t).squeeze(-1)\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), features_t).squeeze(1)\n",
    "        return context, attention_weights\n",
    "\n",
    "\n",
    "class WeightedAttentionFusion(nn.Module):\n",
    "    def __init__(self, title_dim, abstract_dim):\n",
    "        super().__init__()\n",
    "        self.title_weight = nn.Linear(title_dim, 1)\n",
    "        self.abstract_weight = nn.Linear(abstract_dim, 1)\n",
    "\n",
    "    def forward(self, title_repr, abstract_repr):\n",
    "        w_title = self.title_weight(title_repr)\n",
    "        w_abstract = self.abstract_weight(abstract_repr)\n",
    "        weights = torch.cat([w_title, w_abstract], dim=1)\n",
    "        fusion_weights = F.softmax(weights, dim=1)\n",
    "        weighted_title = title_repr * fusion_weights[:, 0:1]\n",
    "        weighted_abstract = abstract_repr * fusion_weights[:, 1:2]\n",
    "        fused = torch.cat([weighted_title, weighted_abstract], dim=1)\n",
    "        return fused, fusion_weights\n",
    "\n",
    "\n",
    "class HybridCNNLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=300, num_filters=160, kernel_sizes=[3,4,5],\n",
    "                 lstm_hidden=160, num_classes=3, dropout=0.5, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            self.embedding.weight.requires_grad = True\n",
    "\n",
    "        self.embed_dropout = nn.Dropout(dropout * 0.4)\n",
    "\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, num_filters, k, padding=k//2) for k in kernel_sizes])\n",
    "        self.conv_bn = nn.ModuleList([nn.BatchNorm1d(num_filters) for _ in kernel_sizes])\n",
    "        self.conv_dropout = nn.Dropout(dropout * 0.3)\n",
    "        total_filters = num_filters * len(kernel_sizes)\n",
    "        \n",
    "        self.cnn_attention = GlobalAttention(total_filters)\n",
    "\n",
    "        self.lstm = nn.LSTM(embed_dim, lstm_hidden, num_layers=2, batch_first=True,\n",
    "                           bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
    "        self.lstm_attention = SelfAttention(lstm_hidden * 2)\n",
    "\n",
    "        self.fusion = WeightedAttentionFusion(lstm_hidden * 2, total_filters)\n",
    "\n",
    "        fused_dim = lstm_hidden * 2 + total_filters\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(fused_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fused_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout * 0.8),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, title_ids, abstract_ids, title_mask=None):\n",
    "        title_embed = self.embed_dropout(self.embedding(title_ids))\n",
    "        lstm_out, _ = self.lstm(title_embed)\n",
    "        title_repr, title_attn = self.lstm_attention(lstm_out, title_mask)\n",
    "\n",
    "        abstract_embed = self.embed_dropout(self.embedding(abstract_ids)).transpose(1, 2)\n",
    "        conv_outputs = []\n",
    "        \n",
    "        for conv, bn in zip(self.convs, self.conv_bn):\n",
    "            x = F.relu(bn(conv(abstract_embed)))\n",
    "            x = self.conv_dropout(x)\n",
    "            conv_outputs.append(x)\n",
    "        \n",
    "        min_len = min(x.size(2) for x in conv_outputs)\n",
    "        conv_outputs = [x[:, :, :min_len] for x in conv_outputs]\n",
    "        \n",
    "        cnn_features = torch.cat(conv_outputs, dim=1)\n",
    "        abstract_repr, abstract_attn = self.cnn_attention(cnn_features)\n",
    "\n",
    "        fused_repr, fusion_weights = self.fusion(title_repr, abstract_repr)\n",
    "        logits = self.classifier(fused_repr)\n",
    "\n",
    "        attention_maps = {\n",
    "            'title_attention': title_attn,\n",
    "            'abstract_attention': abstract_attn,\n",
    "            'fusion_weights': fusion_weights\n",
    "        }\n",
    "        return logits, attention_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class Vocabulary:\n    def __init__(self, max_vocab_size=50000, min_freq=2):\n        self.max_vocab_size = max_vocab_size\n        self.min_freq = min_freq\n        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n        self.word_counts = Counter()\n\n    def build_vocab(self, texts):\n        for text in texts:\n            words = self.tokenize(text)\n            self.word_counts.update(words)\n        filtered_words = [word for word, count in self.word_counts.most_common() if count >= self.min_freq][:self.max_vocab_size - 2]\n        for idx, word in enumerate(filtered_words, start=2):\n            self.word2idx[word] = idx\n            self.idx2word[idx] = word\n\n    @staticmethod\n    def tokenize(text):\n        text = text.lower()\n        text = re.sub(r'[^a-z0-9\\s\\-]', ' ', text)\n        return [w.strip() for w in text.split() if w.strip()]\n\n    def encode(self, text, max_len=None):\n        words = self.tokenize(text)\n        if max_len:\n            words = words[:max_len]\n        return [self.word2idx.get(word, 1) for word in words]\n\n    def __len__(self):\n        return len(self.word2idx)\n\n\ndef load_glove_embeddings(vocab, glove_path, embed_dim=300):\n    embeddings = np.random.randn(len(vocab), embed_dim) * 0.01\n    embeddings[0] = np.zeros(embed_dim)\n\n    found = 0\n    with open(glove_path, 'r', encoding='utf-8') as f:\n        for line in tqdm(f, desc='Loading GloVe'):\n            parts = line.strip().split()\n            if len(parts) != embed_dim + 1:\n                continue\n            word = parts[0]\n            if word in vocab.word2idx:\n                idx = vocab.word2idx[word]\n                try:\n                    embeddings[idx] = np.array([float(x) for x in parts[1:]])\n                    found += 1\n                except (ValueError, IndexError):\n                    continue\n\n    print(f\"Loaded {found}/{len(vocab)} embeddings ({found/len(vocab)*100:.1f}%)\")\n    return torch.FloatTensor(embeddings)\n\n\nclass HybridDataset(Dataset):\n    def __init__(self, titles, abstracts, labels, vocab, max_title_len=30, max_abstract_len=300):\n        self.titles = titles\n        self.abstracts = abstracts\n        self.labels = labels\n        self.vocab = vocab\n        self.max_title_len = max_title_len\n        self.max_abstract_len = max_abstract_len\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        title_ids = self.vocab.encode(self.titles[idx], self.max_title_len)\n        title_len = len(title_ids)\n        title_ids += [0] * (self.max_title_len - title_len)\n\n        abstract_ids = self.vocab.encode(self.abstracts[idx], self.max_abstract_len)\n        abstract_len = len(abstract_ids)\n        abstract_ids += [0] * (self.max_abstract_len - abstract_len)\n\n        title_mask = [1] * title_len + [0] * (self.max_title_len - title_len)\n\n        return {\n            'title_ids': torch.tensor(title_ids, dtype=torch.long),\n            'abstract_ids': torch.tensor(abstract_ids, dtype=torch.long),\n            'title_mask': torch.tensor(title_mask, dtype=torch.float),\n            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n        }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = pd.read_csv(DATASET_PATH)\ndf['category'] = df['category'].replace({'cs.AI': 'cs.AI-LG', 'cs.LG': 'cs.AI-LG'})\n\nprint(f\"Samples: {len(df)}\")\nprint(df['category'].value_counts())\n\nvocab = Vocabulary(max_vocab_size=50000, min_freq=2)\nall_texts = df['title'].tolist() + df['abstract'].tolist()\nvocab.build_vocab(all_texts)\nprint(f\"\\nVocab size: {len(vocab)}\")\n\npretrained_embeddings = load_glove_embeddings(vocab, GLOVE_PATH, embed_dim=300)\n\nle = LabelEncoder()\nlabels = le.fit_transform(df['category'])\n\nX_temp, X_test, y_temp, y_test = train_test_split(\n    df[['title', 'abstract']].values, labels, test_size=0.15, random_state=42, stratify=labels\n)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, test_size=0.15/(1-0.15), random_state=42, stratify=y_temp\n)\n\ntrain_ds = HybridDataset(X_train[:,0], X_train[:,1], y_train, vocab)\nval_ds = HybridDataset(X_val[:,0], X_val[:,1], y_val, vocab)\ntest_ds = HybridDataset(X_test[:,0], X_test[:,1], y_test, vocab)\n\nprint(f\"\\nTrain: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for batch in tqdm(loader, desc='Train'):\n",
    "        title_ids = batch['title_ids'].to(device)\n",
    "        abstract_ids = batch['abstract_ids'].to(device)\n",
    "        title_mask = batch['title_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(title_ids, abstract_ids, title_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return total_loss / len(loader), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Val'):\n",
    "            title_ids = batch['title_ids'].to(device)\n",
    "            abstract_ids = batch['abstract_ids'].to(device)\n",
    "            title_mask = batch['title_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            logits, _ = model(title_ids, abstract_ids, title_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return total_loss / len(loader), acc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 25\n",
    "LR = 0.001\n",
    "DROPOUT = 0.5\n",
    "CLASS_WEIGHTS = [1.0, 1.0, 1.8]\n",
    "LABEL_SMOOTHING = 0.1\n",
    "PATIENCE = 6\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = HybridCNNLSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=300,\n",
    "    num_filters=160,\n",
    "    kernel_sizes=[3,4,5],\n",
    "    lstm_hidden=160,\n",
    "    num_classes=3,\n",
    "    dropout=DROPOUT,\n",
    "    pretrained_embeddings=pretrained_embeddings\n",
    ").to(device)\n",
    "\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "class_weights = torch.FloatTensor(CLASS_WEIGHTS).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=LABEL_SMOOTHING)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "best_val_acc = 0\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "\n",
    "    print(f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | F1: {val_f1:.4f} | Gap: {abs(train_acc-val_acc):.4f}\")\n",
    "\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        print(f\"Best: {val_acc:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stop\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"\\nBest val: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"Test Acc: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Test F1: {test_f1:.4f}\")\n",
    "print(f\"\\n{classification_report(test_labels, test_preds, target_names=le.classes_, digits=4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=le.classes_,\n",
    "            yticklabels=le.classes_, ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix (Counts)')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Greens', xticklabels=le.classes_,\n",
    "            yticklabels=le.classes_, ax=axes[1])\n",
    "axes[1].set_title('Confusion Matrix (Normalized)')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab_size': len(vocab),\n",
    "    'class_names': le.classes_.tolist(),\n",
    "    'num_classes': 3\n",
    "}, 'hybrid_model.pth')\n",
    "\n",
    "print('Model saved: hybrid_model.pth')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
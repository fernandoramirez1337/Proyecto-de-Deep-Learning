{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid CNN-LSTM - ArXiv Classification\n",
    "\n",
    "CNN 1D (abstracts) + Bidirectional LSTM (titles) + Attention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch scikit-learn pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Dataset\n",
    "\n",
    "Upload `arxiv_papers_raw.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('arxiv_papers_raw.csv'):\n",
    "    print(\"Upload arxiv_papers_raw.csv\")\n",
    "else:\n",
    "    print(\"Dataset found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_output, mask=None):\n",
    "        scores = self.attention(lstm_output).squeeze(-1)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), lstm_output).squeeze(1)\n",
    "        return context, attention_weights\n",
    "\n",
    "\n",
    "class GlobalAttention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, cnn_features):\n",
    "        features_t = cnn_features.transpose(1, 2)\n",
    "        scores = self.attention(features_t).squeeze(-1)\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), features_t).squeeze(1)\n",
    "        return context, attention_weights\n",
    "\n",
    "\n",
    "class WeightedAttentionFusion(nn.Module):\n",
    "    def __init__(self, title_dim, abstract_dim):\n",
    "        super().__init__()\n",
    "        self.title_weight = nn.Linear(title_dim, 1)\n",
    "        self.abstract_weight = nn.Linear(abstract_dim, 1)\n",
    "\n",
    "    def forward(self, title_repr, abstract_repr):\n",
    "        w_title = self.title_weight(title_repr)\n",
    "        w_abstract = self.abstract_weight(abstract_repr)\n",
    "        weights = torch.cat([w_title, w_abstract], dim=1)\n",
    "        fusion_weights = F.softmax(weights, dim=1)\n",
    "        weighted_title = title_repr * fusion_weights[:, 0:1]\n",
    "        weighted_abstract = abstract_repr * fusion_weights[:, 1:2]\n",
    "        fused = torch.cat([weighted_title, weighted_abstract], dim=1)\n",
    "        return fused, fusion_weights\n",
    "\n",
    "\n",
    "class HybridCNNLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=300, num_filters=256, kernel_sizes=[3,4,5],\n",
    "                 lstm_hidden=256, num_classes=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.embed_dropout = nn.Dropout(dropout * 0.5)\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv1d(embed_dim, num_filters, k, padding=k//2) for k in kernel_sizes])\n",
    "        self.conv_bn = nn.ModuleList([nn.BatchNorm1d(num_filters) for _ in kernel_sizes])\n",
    "        total_filters = num_filters * len(kernel_sizes)\n",
    "        self.cnn_attention = GlobalAttention(total_filters)\n",
    "        \n",
    "        self.lstm = nn.LSTM(embed_dim, lstm_hidden, num_layers=2, batch_first=True, bidirectional=True, dropout=dropout if dropout > 0 else 0)\n",
    "        self.lstm_attention = SelfAttention(lstm_hidden * 2)\n",
    "        \n",
    "        self.fusion = WeightedAttentionFusion(lstm_hidden * 2, total_filters)\n",
    "        \n",
    "        fused_dim = lstm_hidden * 2 + total_filters\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.BatchNorm1d(fused_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(fused_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(dropout * 0.8),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, title_ids, abstract_ids, title_mask=None):\n",
    "        title_embed = self.embed_dropout(self.embedding(title_ids))\n",
    "        lstm_out, _ = self.lstm(title_embed)\n",
    "        title_repr, title_attn = self.lstm_attention(lstm_out, title_mask)\n",
    "        \n",
    "        abstract_embed = self.embed_dropout(self.embedding(abstract_ids)).transpose(1, 2)\n",
    "        conv_outputs = []\n",
    "        for conv, bn in zip(self.convs, self.conv_bn):\n",
    "            x = F.relu(bn(conv(abstract_embed)))\n",
    "            conv_outputs.append(x)\n",
    "        cnn_features = torch.cat(conv_outputs, dim=1)\n",
    "        abstract_repr, abstract_attn = self.cnn_attention(cnn_features)\n",
    "        \n",
    "        fused_repr, fusion_weights = self.fusion(title_repr, abstract_repr)\n",
    "        logits = self.classifier(fused_repr)\n",
    "        \n",
    "        attention_maps = {\n",
    "            'title_attention': title_attn,\n",
    "            'abstract_attention': abstract_attn,\n",
    "            'fusion_weights': fusion_weights\n",
    "        }\n",
    "        return logits, attention_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, max_vocab_size=50000, min_freq=2):\n",
    "        self.max_vocab_size = max_vocab_size\n",
    "        self.min_freq = min_freq\n",
    "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "        self.word_counts = Counter()\n",
    "\n",
    "    def build_vocab(self, texts):\n",
    "        for text in texts:\n",
    "            words = self.tokenize(text)\n",
    "            self.word_counts.update(words)\n",
    "        filtered_words = [word for word, count in self.word_counts.most_common() if count >= self.min_freq][:self.max_vocab_size - 2]\n",
    "        for idx, word in enumerate(filtered_words, start=2):\n",
    "            self.word2idx[word] = idx\n",
    "            self.idx2word[idx] = word\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s\\-]', ' ', text)\n",
    "        return [w.strip() for w in text.split() if w.strip()]\n",
    "\n",
    "    def encode(self, text, max_len=None):\n",
    "        words = self.tokenize(text)\n",
    "        if max_len:\n",
    "            words = words[:max_len]\n",
    "        return [self.word2idx.get(word, 1) for word in words]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)\n",
    "\n",
    "\n",
    "class HybridDataset(Dataset):\n",
    "    def __init__(self, titles, abstracts, labels, vocab, max_title_len=30, max_abstract_len=200):\n",
    "        self.titles = titles\n",
    "        self.abstracts = abstracts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "        self.max_title_len = max_title_len\n",
    "        self.max_abstract_len = max_abstract_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title_ids = self.vocab.encode(self.titles[idx], self.max_title_len)\n",
    "        title_len = len(title_ids)\n",
    "        title_ids += [0] * (self.max_title_len - title_len)\n",
    "        \n",
    "        abstract_ids = self.vocab.encode(self.abstracts[idx], self.max_abstract_len)\n",
    "        abstract_len = len(abstract_ids)\n",
    "        abstract_ids += [0] * (self.max_abstract_len - abstract_len)\n",
    "        \n",
    "        title_mask = [1] * title_len + [0] * (self.max_title_len - title_len)\n",
    "        \n",
    "        return {\n",
    "            'title_ids': torch.tensor(title_ids, dtype=torch.long),\n",
    "            'abstract_ids': torch.tensor(abstract_ids, dtype=torch.long),\n",
    "            'title_mask': torch.tensor(title_mask, dtype=torch.float),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('arxiv_papers_raw.csv')\n",
    "print(f\"Samples: {len(df)}\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df['category'])\n",
    "\n",
    "vocab = Vocabulary(max_vocab_size=50000, min_freq=2)\n",
    "all_texts = df['title'].tolist() + df['abstract'].tolist()\n",
    "vocab.build_vocab(all_texts)\n",
    "print(f\"Vocab size: {len(vocab)}\")\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    df[['title', 'abstract']].values, labels, test_size=0.15, random_state=42, stratify=labels\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.15/(1-0.15), random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "train_ds = HybridDataset(X_train[:,0], X_train[:,1], y_train, vocab)\n",
    "val_ds = HybridDataset(X_val[:,0], X_val[:,1], y_val, vocab)\n",
    "test_ds = HybridDataset(X_test[:,0], X_test[:,1], y_test, vocab)\n",
    "\n",
    "print(f\"Train: {len(train_ds)} | Val: {len(val_ds)} | Test: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "LR = 0.001\n",
    "DROPOUT = 0.5\n",
    "CLASS_WEIGHTS = [2.0, 1.0, 1.0, 1.0]\n",
    "PATIENCE = 5\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "model = HybridCNNLSTM(\n",
    "    vocab_size=len(vocab),\n",
    "    embed_dim=300,\n",
    "    num_filters=256,\n",
    "    kernel_sizes=[3,4,5],\n",
    "    lstm_hidden=256,\n",
    "    num_classes=4,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "print(f\"Params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "class_weights = torch.FloatTensor(CLASS_WEIGHTS).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    for batch in tqdm(loader, desc='Train'):\n",
    "        title_ids = batch['title_ids'].to(device)\n",
    "        abstract_ids = batch['abstract_ids'].to(device)\n",
    "        title_mask = batch['title_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, _ = model(title_ids, abstract_ids, title_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(loader), accuracy_score(all_labels, all_preds)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc='Val'):\n",
    "            title_ids = batch['title_ids'].to(device)\n",
    "            abstract_ids = batch['abstract_ids'].to(device)\n",
    "            title_mask = batch['title_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            logits, _ = model(title_ids, abstract_ids, title_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            all_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return total_loss / len(loader), acc, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
    "best_val_acc = 0\n",
    "best_model_state = None\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    \n",
    "    print(f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | F1: {val_f1:.4f} | Gap: {abs(train_acc-val_acc):.4f}\")\n",
    "    \n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "        print(f\"Best: {val_acc:.4f}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stop\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "print(f\"\\nBest val: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, test_f1, test_preds, test_labels = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Acc: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"Test F1: {test_f1:.4f}\")\n",
    "print(f\"\\n{classification_report(test_labels, test_preds, target_names=le.classes_, digits=4)}\")\n",
    "\n",
    "cs_ai_recall = classification_report(test_labels, test_preds, target_names=le.classes_, output_dict=True)['cs.AI']['recall']\n",
    "print(f\"\\nAcc >=60%: {test_acc >= 0.60} | cs.AI >30%: {cs_ai_recall > 0.30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'vocab_size': len(vocab),\n",
    "    'class_names': le.classes_\n",
    "}, 'best_hybrid_model.pth')\n",
    "\n",
    "with open('vocab_hybrid.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "print(\"Saved: best_hybrid_model.pth, vocab_hybrid.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train', marker='o')\n",
    "axes[0].plot(history['val_loss'], label='Val', marker='o')\n",
    "axes[0].set_title('Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train', marker='o')\n",
    "axes[1].plot(history['val_acc'], label='Val', marker='o')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sample = test_ds[0]\n",
    "title_ids = sample['title_ids'].unsqueeze(0).to(device)\n",
    "abstract_ids = sample['abstract_ids'].unsqueeze(0).to(device)\n",
    "title_mask = sample['title_mask'].unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits, attn_maps = model(title_ids, abstract_ids, title_mask)\n",
    "    pred = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "title_attn = attn_maps['title_attention'].cpu().numpy()[0]\n",
    "abstract_attn = attn_maps['abstract_attention'].cpu().numpy()[0]\n",
    "fusion_weights = attn_maps['fusion_weights'].cpu().numpy()[0]\n",
    "\n",
    "print(f\"Prediction: {le.classes_[pred]}\")\n",
    "print(f\"True label: {le.classes_[sample['label']]}\")\n",
    "print(f\"Fusion weights - Title: {fusion_weights[0]:.3f}, Abstract: {fusion_weights[1]:.3f}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 4))\n",
    "axes[0].bar(range(len(title_attn[:20])), title_attn[:20])\n",
    "axes[0].set_title('Title Attention (first 20 tokens)')\n",
    "axes[1].bar(range(len(abstract_attn[:50])), abstract_attn[:50])\n",
    "axes[1].set_title('Abstract Attention (first 50 tokens)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('attention.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('best_hybrid_model.pth')\n",
    "files.download('vocab_hybrid.pkl')\n",
    "files.download('history.png')\n",
    "files.download('attention.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
